<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Carles Gelada">
<meta name="author" content="Jacob Buckman">
<meta name="dcterms.date" content="2024-09-23">

<title>Why Gradient Descent Minimizes Training Loss – Manifest AI</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<link href="../../favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V0D26E23Q3"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-V0D26E23Q3', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Why Gradient Descent Minimizes Training Loss">
<meta property="og:description" content="Convexity is unnecessary to guarantee convergence to low loss">
<meta property="og:image" content="/thumbnails/gd-minimizes-loss.png">
<meta property="og:site_name" content="Manifest AI">
<meta name="twitter:title" content="Why Gradient Descent Minimizes Training Loss">
<meta name="twitter:description" content="Convexity is unnecessary to guarantee convergence to low loss">
<meta name="twitter:image" content="https://manifestai.com/thumbnails/gd-minimizes-loss.png">
<meta name="twitter:creator" content="@manifest__ai">
<meta name="twitter:site" content="@manifest__ai">
<meta name="twitter:card" content="summary">
<meta name="citation_title" content="Why Gradient Descent Minimizes Training Loss">
<meta name="citation_author" content="Carles Gelada">
<meta name="citation_author" content="Jacob Buckman">
<meta name="citation_publication_date" content="2024-09-23">
<meta name="citation_cover_date" content="2024-09-23">
<meta name="citation_year" content="2024">
<meta name="citation_online_date" content="2024-09-23">
<meta name="citation_language" content="en">
<meta name="citation_publisher" content="Manifest AI">
<meta name="citation_reference" content="citation_title=Gradient descent provably optimizes over-parameterized neural networks;,citation_author=Simon S. Du;,citation_author=Xiyu Zhai;,citation_author=Barnabas Poczos;,citation_author=Aarti Singh;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://arxiv.org/abs/1810.02054;">
<meta name="citation_reference" content="citation_title=A convergence theory for deep learning via over-parameterization;,citation_author=Zeyuan Allen-Zhu;,citation_author=Yuanzhi Li;,citation_author=Zhao Song;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://arxiv.org/abs/1811.03962;">
<meta name="citation_reference" content="citation_title=Understanding deep learning requires rethinking generalization;,citation_author=Chiyuan Zhang;,citation_author=Samy Bengio;,citation_author=Moritz Hardt;,citation_author=Benjamin Recht;,citation_author=Oriol Vinyals;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://arxiv.org/abs/1611.03530;">
<meta name="citation_reference" content="citation_title=Gradient descent finds global minima of deep neural networks;,citation_author=Simon S. Du;,citation_author=Jason D. Lee;,citation_author=Haochuan Li;,citation_author=Liwei Wang;,citation_author=Xiyu Zhai;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://arxiv.org/abs/1811.03804;">
<meta name="citation_reference" content="citation_title=Convex optimization: Algorithms and complexity;,citation_author=Sébastien Bubeck;,citation_author=others;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=3-4;,citation_volume=8;,citation_journal_title=Foundations and Trends in Machine Learning;,citation_publisher=Now Publishers, Inc.;">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../m-logo-tight.png" alt="" class="navbar-logo">
    </a>
  </div>
          <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://discord.gg/aFsCgDraGP"> <i class="bi bi-discord" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/manifest__ai"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
   
  <ul>
  <li><a href="#notation-and-definitions" id="toc-notation-and-definitions" class="nav-link active" data-scroll-target="#notation-and-definitions">0. Notation and Definitions</a></li>
  <li><a href="#learning-with-gradient-flows" id="toc-learning-with-gradient-flows" class="nav-link" data-scroll-target="#learning-with-gradient-flows">1. Learning with Gradient Flows</a></li>
  <li><a href="#a-replacement-for-convexity" id="toc-a-replacement-for-convexity" class="nav-link" data-scroll-target="#a-replacement-for-convexity">2. A Replacement for Convexity</a></li>
  <li><a href="#the-simplest-neural-network" id="toc-the-simplest-neural-network" class="nav-link" data-scroll-target="#the-simplest-neural-network">3. The Simplest Neural Network</a>
  <ul class="collapse">
  
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Why Gradient Descent Minimizes Training Loss</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Carles Gelada </p>
             <p>Jacob Buckman </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 23, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="hidden">
<p><span class="math display">\[
\newcommand{\R}{\mathbb{R}}
\newcommand{\der}{\partial}
\newcommand{\dldt}{\frac{\der l}{\der t}}
\newcommand{\len}{\text{length}}
\newcommand{\en}{\text{energy}}
\newcommand{\relu}{ {\small\text{ReLU}} }
\newcommand{\dim}{\text{dim}}
\newcommand{\tr}{\text{trace}}
\newcommand{\lin}{\text{Lin}}
\newcommand{\rnk}{\text{rank}}
\newcommand{\ht}{\widehat}
\newcommand{\dwdt}{\frac{\der w}{\der t}}
\newcommand{\l}{\mathscr{l}}
\newcommand{\E}{\mathbb E}
\]</span></p>
</div>
<style>
summary {
  cursor: pointer;
  padding: 8px;
  background-color: #f0f0f0; /* Light grey background */
  border-radius: 8px; /* Rounded corners for consistency */
}

/* Hover state changes the background color to a lighter grey */
summary:hover {
  background-color: #e0e0e0; /* Lighter grey on hover */
}

/* Override hover effect when details is open */
details[open] summary:hover {
  background-color: #f0f0f0; /* Maintain the same color as the non-hover state */
}

details[open] summary {
  padding: 8px;
}

details {
  padding: 0; /* No padding when details is not open */
  border-radius: 8px; /* Rounded corners for consistency */
  background-color: #f0f0f0; /* Light grey background */
}

details[open] {
  padding: 8px; /* Padding inside the details for content alignment */
}
</style>
<p>Every student of deep learning has wondered some point in their journey: “How can gradient descent on a neural network possibly succeed? Surely, on such a large and non-convex loss landscape, we will get stuck in some local minimum, far from the optimal solution.” And yet, deep learning practitioners quickly learn to trust that a large enough neural network with properly tuned hyper-parameters will successfully fit any training data we throw at it <span class="citation" data-cites="zhang2017understandingdeeplearningrequires"><a href="#ref-zhang2017understandingdeeplearningrequires" role="doc-biblioref">[1]</a></span>. In this article, we explore a mathemathematical theory to explain this surprising phenomenon.</p>
<p>One common approach to showing that gradient descent will converge to a global optimum is to show that the loss landscape is <em>convex</em>, which means that a line drawn between any pair of points will never intersect its surface. This property can be used to prove that no local minima exist <span class="citation" data-cites="bubeck2015convex"><a href="#ref-bubeck2015convex" role="doc-biblioref">[2]</a></span>. But unfortunately, this technique cannot be applied to neural networks, as the loss function of a neural network is not a convex function of its parameters. This can be demonstrated by a simple counterexample.</p>
<details>
<summary>
Neural network convexity counterexample
</summary>
<p>Consider a 2-layer MLP with ReLU nonlinearity, trained with the L2 loss on a single data point. It has two parameter matrices <span class="math inline">\(M\in \R^{k\times m}\)</span> and <span class="math inline">\(N\in \R^{n\times k}\)</span>. Given an input <span class="math inline">\(x \in \R^m\)</span> the MLP produces the output <span class="math display">\[y = N \: \relu(M x)\]</span> And the loss is <span class="math inline">\(\l = \frac 1 2 | y - q|^2\)</span> where <span class="math inline">\(q \in \R^n\)</span> is the target corresponding to the input <span class="math inline">\(x\)</span>.</p>
<p>Let <span class="math inline">\(m=n=1\)</span> and <span class="math inline">\(k=2\)</span>. Our input-output pair is just <span class="math inline">\(x=1\)</span> and <span class="math inline">\(q=0\)</span>. To show that the function is not convex, we will interpolate the loss between two parameter vectors <span class="math inline">\(w = (N, M)\)</span> and <span class="math inline">\(w' = (N', M')\)</span> where <span class="math display">\[
N = \begin{bmatrix} 0  &amp; 1 \end{bmatrix}
\quad
M = \begin{bmatrix} 1 \\ 0 \end{bmatrix}
\quad\quad
N' = \begin{bmatrix} 1 &amp; 0 \end{bmatrix}
\quad
M' = \begin{bmatrix} 0 \\ 1 \end{bmatrix}
\]</span></p>
Since the target <span class="math inline">\(q=0\)</span> it’s clear that the loss at <span class="math inline">\(w\)</span> and <span class="math inline">\(w'\)</span> is <span class="math inline">\(0\)</span>. But if we define <span class="math inline">\(u = s w + (1-s) w'\)</span> you can check that the loss at <span class="math inline">\(u\)</span> is <span class="math inline">\(\frac 1 2 s^2 (1-s)^2\)</span> which, for <span class="math inline">\(s \in (0, 1)\)</span> is greater than <span class="math inline">\(0\)</span>. Thus, the surface of the loss landscape must intersect the line drawn between these two points, and so it is not convex.
</details>
<p>However, while convexity is <em>sufficient</em> to prove convergence, it is not <em>required</em> for convergence to occur. For example, look at the plot below. On the left, we see the loss landscape for a quadratic loss on a two-dimensional parameter space. On the right, we see a loss landscape that is similar, except that it has a bulge that clearly makes it non-convex. And yet it is visually evident that neither plot has local minima. Gradient descent would optimize successfully in both settings.</p>
<div class="column-body" style="text-align: center;">
<div style="display: flex; justify-content: center; align-items: center;">
<iframe src="3d_loss_plots.html" width="400" height="220" style="border:none; margin: auto;" scrolling="no">
</iframe>
</div>
</div>
<p>In this article, we investigate an alternative property to convexity which we call <em>learning health</em>. Informally, it says that if the loss is large, the gradient must also be large. (In the plot above, both loss landscapses are healthy.)</p>
<p>The central result of this article is to use learning health to prove that gradient descent on neural networks will decrease the loss to a small value. The argument goes like this:</p>
<ul>
<li>The neural network is healthy near the initialization.</li>
<li>When the loss landscape is healthy, the loss will decrease exponentially quickly.</li>
<li>Under the dynamics of gradient descent, the parameters will stay close to initialization for a some time.</li>
</ul>
<p>These three results allow us to conclude that the loss decays exponentially for a meaningful amount of time, and therefore is guaranteed to reach some small value. In general, we observe that the bounds we derive are improved by the size of the neural network, so when using a large enough network, the loss can be guaranteed to fall arbitrarily close to zero.</p>
<p>In this article, we apply this theory only to a very simple neural network: a 2-layer MLP trained with the L2 loss on a dataset consisting of a single datapoint. But the general theory we develop here applies more broadly. In follow-up posts, we will show that the results can also be applied to MLPs with multiple layers, trained on multiple data points, and using the cross-entropy loss instead of the L2. There is also existing literature exploring similar ideas (see e.g. <span class="citation" data-cites="zhang2017understandingdeeplearningrequires du2019gradientdescentfindsglobal allenzhu2019convergencetheorydeeplearning"><a href="#ref-zhang2017understandingdeeplearningrequires" role="doc-biblioref">[1]</a>, <a href="#ref-du2019gradientdescentfindsglobal" role="doc-biblioref">[3]</a>, <a href="#ref-allenzhu2019convergencetheorydeeplearning" role="doc-biblioref">[4]</a></span>).</p>
<p>The plot below visualizes the bound we derive, juxtaposed with the actual training curve of a neural network. Every time you click the train button a new set of initial parameters, inputs, and targets are randomly initialized, and 200 steps of gradient descent training are performed. You can see for yourself that the loss always approaches 0, and that our bound is non-vacuous.</p>
<div id="loss-chart-root">

</div>
<section id="notation-and-definitions" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="notation-and-definitions">0. Notation and Definitions</h2>
<p>Much of the theory in this article treats the space of parameters as a vector space equipped with an inner product. The parameters of a neural network tend to either be elements of <span class="math inline">\(\R^{n}\)</span> or matrices in <span class="math inline">\(\R^{n\times m}\)</span>, so we need to define suitable inner products for these two types of vectors.</p>
<p><strong>Definition 0.1: Inner Product.</strong> For two vectors <span class="math inline">\(x,y \in \R^n\)</span> we take the inner product to be <span class="math inline">\(&lt;x, y&gt; = x^T y\)</span>. For two matrices <span class="math inline">\(M,N\in \R^{n\times m}\)</span> we use <span class="math inline">\(&lt;M, N&gt; = \tr(M^T N)\)</span>. Any inner product induces a norm <span class="math inline">\(|\cdot|\)</span> via <span class="math inline">\(|v| = \sqrt{&lt;v,v&gt;}\)</span>, and you can verify that, in the <span class="math inline">\(\R^n\)</span> and <span class="math inline">\(\R^{n\times m}\)</span> cases, this induced norm takes the following forms: <span class="math display">\[\begin{align}
|x| = \sqrt{\sum_i x_i^2} \quad\quad |M| = \sqrt{\sum_{ij} M_{ij}^2}
\end{align}\]</span> which are also known as the L2 norms of the respective vector spaces. <span class="math inline">\(\blacksquare\)</span></p>
<p><strong>Definition 0.2: Derivative.</strong> Let <span class="math inline">\(f: V \to W\)</span> be a function between two vector spaces. The derivative at a point <span class="math inline">\(v\in V\)</span> is a linear function <span class="math inline">\(\der f(v): V\to W\)</span>. It tells us how changing the input <span class="math inline">\(v \to v + u\)</span> will affect the output, if the change <span class="math inline">\(u\in V\)</span> is small. Concretely, <span class="math display">\[
\der f(v)(u) \simeq f(v + u) - f(v)
\]</span> Some people would call <span class="math inline">\(\der f(v)(u)\)</span> the directional derivative of <span class="math inline">\(f\)</span> along <span class="math inline">\(u\)</span> at a point <span class="math inline">\(v\)</span>. <span class="math inline">\(\blacksquare\)</span></p>
<p><strong>Definition 0.3: Path Derivative.</strong> An especially important case is when we are taking the derivative of a function <span class="math inline">\(h:\R \to V\)</span>, also known as a <em>path</em> through <span class="math inline">\(V\)</span>. Here, using the notation <span class="math inline">\(\der h(t): \R \to V\)</span> is a little cumbersome. Instead, we can use Newton’s notation, which defines <span class="math inline">\(h'(t) = \der h(t)(1)\in V\)</span>. This allows us to think of the derivative of <span class="math inline">\(h\)</span> as a vector in <span class="math inline">\(V\)</span>, as opposed to a map <span class="math inline">\(\R \to V\)</span>. This is possible because any linear map of the form <span class="math inline">\(M: \R \to V\)</span> can be turned into scalar-vector multiplication <span class="math inline">\(M(r) = r \: v\)</span> by defining <span class="math inline">\(v = M(1)\)</span>. <span class="math inline">\(\blacksquare\)</span></p>
<p>One important use of the derivative of a path is to define the length and energy of the path.</p>
<p><strong>Definition 0.4: length and energy of a path.</strong> Given a normed vector space <span class="math inline">\(V\)</span> and a differentiable path <span class="math inline">\(h: [0, t] \to V\)</span>, the length and energy of the path are defined as <span class="math display">\[\begin{align}
\len(h) &amp;= \int_0^t |h'(s)| ds \\
\en(h) &amp;= \int_0^t |h'(s)|^2 ds
\end{align}\]</span> <span class="math inline">\(\blacksquare\)</span></p>
<p><strong>Definition 0.5: Gradient.</strong> Given a vector space <span class="math inline">\(V\)</span> equipped with an inner product, the gradient of a differentiable function <span class="math inline">\(f: V \to \R\)</span>, denoted <span class="math inline">\(\nabla f\)</span>, is a map <span class="math inline">\(\nabla f: V\to V\)</span> defined so that <span class="math inline">\(\nabla f(v)\in V\)</span> is the unique vector satisfying <span class="math display">\[
\der f(v)(u) = &lt;\nabla f(v), u&gt; \quad \forall v\in V
\]</span> Whenever it is completely clear from the context which function <span class="math inline">\(f\)</span> we are taking the gradient of we can use the shorthand <span class="math inline">\(\hat v = \nabla f(v)\)</span>. <span class="math inline">\(\blacksquare\)</span></p>

<div class="no-row-height column-margin column-container"><div class="">
<p>You might be used to a different definition of the gradient. The one you know turns out to be equivalent to the one we introduce here. Take a look at <a href="https://charlesfrye.github.io/math/2018/03/06/frechet-derivative-introduction.html">this great article</a> for an in-depth explanation.</p>
</div></div><p><strong>Definition 0.6: Gradient Flow.</strong> Let <span class="math inline">\(V\)</span> be a vector space with an inner product. Given a differentiable and lower-bounded function <span class="math inline">\(f: V\to \R\)</span>, the gradient flow starting at <span class="math inline">\(v_0\in V\)</span> is defined as the path <span class="math inline">\(\gamma: [0, \infty) \to V\)</span> satisfying <span class="math display">\[
\gamma(0) = v_0  \quad\text{and}\quad \gamma'(t) = - \nabla f\circ \gamma(t)
\]</span> The existence of <span class="math inline">\(\gamma\)</span> follows from the existence and uniqueness of partial differential equations. The fact that <span class="math inline">\(f\)</span> is lower-bounded guarantees that the solution never diverges, and so <span class="math inline">\(\gamma\)</span> is a map with domain <span class="math inline">\([0, \infty)\)</span>. <span class="math inline">\(\blacksquare\)</span></p>
</section>
<section id="learning-with-gradient-flows" class="level2">
<h2 class="anchored" data-anchor-id="learning-with-gradient-flows">1. Learning with Gradient Flows</h2>
<p><strong>Definition 1.1: Learning Problem.</strong> The problem setup consists of a tuple <span class="math inline">\((W, w_0, f)\)</span> where:</p>
<ul>
<li><p><span class="math inline">\(W\)</span> is the parameter space, which controls the behavior of the model. Mathematically, it is a vector space equipped with an inner product <span class="math inline">\(&lt;\cdot, \cdot&gt;\)</span>.</p></li>
<li><p><span class="math inline">\(w_0\in W\)</span> is the initial point from which the learning will proceed.</p></li>
<li><p><span class="math inline">\(f: W \to \R^+\)</span> is the loss function, which tells us how good the parameters are (presumably at fitting some dataset). The lower the loss, the better the parameters. A loss function must be lower bounded so it’s nice to assume wlog that <span class="math inline">\(\inf_{w} f(w) = 0\)</span>.</p></li>
</ul>
<p>Out of <span class="math inline">\(f, W\)</span> and <span class="math inline">\(w_0\)</span>, the following objects are defined:</p>
<ul>
<li><p>A path <span class="math inline">\(\gamma: [0, \infty) \to W\)</span> is a gradient flow of <span class="math inline">\(f\)</span> starting at <span class="math inline">\(w_0\)</span>. It describes the evolution of the parameters through time.</p></li>
<li><p>A loss curve <span class="math inline">\(\l:\R \to \R\)</span>, defined as <span class="math inline">\(\l(t) = f\circ \gamma(t)\)</span>, tells us the amount of loss at any moment in time.</p></li>
</ul>
<p><span class="math inline">\(\blacksquare\)</span></p>
<p>This setting is deeply connected to the learning algorithms used in practice to train neural networks. But it is worth pointing out some important differences:</p>
<ul>
<li>Learning algorithms used in practice have discrete aspects. For example, gradient descent starts with the initial parameters <span class="math inline">\(w_0\in W\)</span> and repeatedly applies the update <span class="math inline">\(w_{t+1} = w_t - \delta \nabla f(w_t)\)</span> for some learning rate hyperparameter <span class="math inline">\(\delta \in \R^+\)</span>. Clearly, in the limit <span class="math inline">\(\delta \to 0\)</span> this discrete path converges to the gradient flow <span class="math inline">\(\gamma\)</span>. But it is less clear whether the learning rates used in practice are small enough for the gradient flow to be a good approximation.</li>
<li>Modern deep learning always uses <em>stochastic</em> gradient descent (SGD). Instead of computing the gradient on the entire dataset, we estimate it by computing the average gradient on a small random subset of the data. These stochastic gradients result in slightly worse updates, but they are much cheaper to compute. This tradeoff is worth making because, for the same amount of compute, it allows us apply many more updates. Again, as the learning rate approaches <span class="math inline">\(0\)</span>, SGD converges to the gradient flow. But it is worth asking whether or not this approximation applies in practice.</li>
<li>It’s common for deep learning optimizers to include details like a momentum term, a correction for the variance, etc… each of these details is yet another reason why practical algorithms may look quite different from gradient flow.</li>
</ul>
<p>Ultimately, we will want to prove guarantees for the algorithms we run in practice. But studying the behavior of gradient flows is a useful intermediate step. The rest of this section will lay out some of the key mathematical properties of gradient flows that make them so powerful when deriving learning guarantees.</p>
<p><strong>Result 1.2.</strong> The derivative of the loss curve satisfies: <span class="math display">\[\l'(t) = - | \nabla f\circ \gamma(t)| ^2\]</span></p>
<details>
<summary>
Proof
</summary>
<p>For simplicity let <span class="math inline">\(w=\gamma(t)\)</span>. Then, <span class="math display">\[\begin{align}
\l'(t) &amp;= \der f(w)( \gamma'(t))
&amp;\quad &amp;\text{(chain rule)} \\
&amp;= &lt; \nabla f(w), \gamma'(t)&gt;
&amp;\quad &amp;\text{(gradient def.)} \\
&amp;= -&lt; \nabla f(w), \nabla f(w)&gt;
&amp;\quad &amp;\text{(gradient flow def.)} \\
&amp;= - | \nabla f\circ \gamma(t)| ^2
\end{align}\]</span></p>
</details>
<p>So, under gradient flow, the magnitude of the gradient tells us how fast the loss is decreasing at any moment in tme. A large gradient means fast learning! A consequence of this result is that <span class="math inline">\(\en(\gamma)\)</span> measures how much the path <span class="math inline">\(\gamma\)</span> has managed to reduce the loss.</p>
<p><strong>Result 1.3.</strong> Let <span class="math inline">\(f:W \to \R\)</span> be a differentiable function and <span class="math inline">\(\gamma:[0, t] \to W\)</span> be a gradient flow of <span class="math inline">\(f\)</span> as in definition 1.1. Then:</p>
<p><span class="math display">\[
\en(\gamma) = \l(0) - \l(t)
\]</span></p>
<details>
<summary>
Proof
</summary>
<p><span class="math display">\[\begin{align}
\en(\gamma) &amp;= \int_0^t |\gamma'(s)|^2 ds \\
&amp;= \int_0^t |\nabla f \circ \gamma(s)|^2 ds
&amp;\quad &amp;\text{(gradient flow def.)} \\
&amp;= - \int_0^t  \l'(s) ds
&amp;\quad &amp;\text{(result 1.2)} \\
&amp;= \l(0) - \l(t)
\end{align}\]</span></p>
</details>
<p>Thus, we can reformulate questions about <span class="math inline">\(\l(t)\)</span> into questions about <span class="math inline">\(\en(\gamma)\)</span>; an interesting shift in perspective. For our purposes, the most important implication is that <span class="math inline">\(\en(\gamma) \le \l(0)\)</span>, i.e., the energy is bounded by the initial loss. This follows from Result 1.3 and from the assumption in Definition 1.1 that <span class="math inline">\(f(w) \ge 0\)</span>.</p>
<p>The last step before we are ready to prove the main result of this section is to establish an inequality between the length and energy of a generic path (not necessarily a gradient flow).</p>
<p><strong>Result 1.4.</strong> If <span class="math inline">\(h: [0, t] \to V\)</span> is a differentiable path, then</p>
<p><span class="math display">\[
\len(h)^2 \le t\;  \en(h)
\]</span></p>
<details>
<summary>
Proof
</summary>
Just note that <span class="math display">\[\begin{align}
\len(h) &amp;=  \int_0^t |h'(s)| ds  \\
&amp;\le  \sqrt{\int_0^t  1^2 ds } \sqrt{\int_0^t | h'(s)|^2 ds } \;\;\;\;\;\; \text{(by Cauchy Schwarz)} \\
&amp;\le\sqrt{ t \; \en(h)} \\
\end{align}\]</span> From which the result follows.
</details>
<p>We are finally ready to show that, in a short amount of time <span class="math inline">\(t\)</span>, the parameters <span class="math inline">\(\gamma(t)\)</span> cannot move very far away from the initialization.</p>
<p><strong>Result 1.5.</strong> Let <span class="math inline">\(\gamma\)</span> be the gradient flow of <span class="math inline">\(f\)</span> starting at <span class="math inline">\(w_0\)</span> as in Definition 1.1. Then: <span class="math display">\[
|\gamma(t) - w_0| \le \sqrt{t\;\l(0)}
\]</span></p>
<details>
<summary>
Proof
</summary>
<span class="math display">\[\begin{align}
|\gamma(t) - \gamma(0)|
&amp;= \left |\int_0^t  \gamma'(s) ds \right| \\
&amp;\le \int_0^t  \left | \gamma'(s) \right| ds
&amp;\quad &amp;\text{(triangle inequality for integrals)} \\
&amp;= \len(\gamma) \\
&amp;\le \sqrt{t \; \en(\gamma)}
&amp;\quad &amp;\text{(result 1.4)}
\end{align}\]</span>
</details>
</section>
<section id="a-replacement-for-convexity" class="level2">
<h2 class="anchored" data-anchor-id="a-replacement-for-convexity">2. A Replacement for Convexity</h2>
<p>As described in the introduction, our proof utilizes the concept of <em>learning health</em> instead of convexity, which we define the following way: a loss function <span class="math inline">\(f : W \to \mathbb{R}^+\)</span> has <em>learning health</em> if there exists <span class="math inline">\(\alpha \in \R^+\)</span> such that for all <span class="math inline">\(w \in W\)</span>, <span class="math display">\[
\frac{|\nabla f(w)|^2}{f(w)}  \ge \alpha
\]</span> One implication of this definition is that no local minima can exist in a healthy loss landscape. After all, the definition of a local minimum is a point <span class="math inline">\(w\)</span> with no gradient but high loss, the existence of which is ruled out by the condition.</p>
<p>But the following result tells us that learning health also implies something much stronger. On a healthy loss landscape, the loss of a gradient flow is guaranteed to decay to <span class="math inline">\(0\)</span> exponentially quickly.</p>
<p><strong>Result 2.1.</strong> If <span class="math inline">\(f: W\to \R^+\)</span> satisfies <span class="math inline">\(\frac{|\nabla f(w)|^2}{f(w)}  \ge \alpha\)</span> for some <span class="math inline">\(\alpha \in \R^+\)</span>, then <span class="math display">\[
\l(t) \le \l(0) \; e^{-\alpha t}
\]</span></p>
<details open="">
<summary>
Proof
</summary>
<span class="math display">\[\begin{align}
\frac{\der \ln \l(t)}{\der t} &amp;= \frac{\l'(t)}{\l(t)}
= -\frac{|\nabla f \circ \gamma(t)|^2}{f\circ \gamma(t)}
\le  -\alpha \\
\end{align}\]</span> so <span class="math display">\[
\ln \l(t) - \ln \l(0) = \int_0^t \frac{\der \ln \l(s)}{\der s}  ds \le - \int_0^t \alpha ds = - \alpha t
\]</span> And then <span class="math inline">\(\ln \l(t)  \le  \ln \l(0) - \alpha t\)</span>. To conclude, use the fact that exponential is a monotone function and <span class="math display">\[
\l(t) = e^{\ln \l(t)} \le  e^{\ln \l(0) - \alpha t} = \l(0) e^{ - \alpha t}
\]</span>
</details>
<p>Unfortunately, neural networks don’t satisfy the learning health property for for all <span class="math inline">\(w\in W\)</span>. (To see that, just consider an MLP with “degenerate” parameters, where all the weight matrices are <span class="math inline">\(0\)</span>. That MLP will have 0 gradient, even when it has high loss.) But that does not prevent us from using learning health to derive guarantees. In Section 3 we will see that a properly-initialized 2-layer MLP does indeed satisfy a relaxed version of this property: there exists <span class="math inline">\(\alpha,\beta \in \R^+\)</span> such that for all <span class="math inline">\(w \in W\)</span>, <span class="math display">\[
\frac{|\nabla f(w)|^2}{f(w)}  \ge \alpha - \beta \; |w-w_0|
\]</span></p>
<p>The main result of this section is a guarantee that can be applied to any learning problem satisfying this relaxed property.</p>
<p><strong>Result 2.2.</strong> If <span class="math inline">\(f\)</span> and <span class="math inline">\(w_0\)</span> satisfy <span class="math inline">\(\frac{|\nabla f(w)|^2}{f(w)}  \ge \alpha - \beta \; |w-w_0|\)</span> for all <span class="math inline">\(w\in W\)</span>, then <span class="math display">\[
l(\infty) \le \l(0) \; \exp({-\frac {\alpha^3}{3 \beta^2 \l(0)} })
\]</span></p>
<details>
<summary>
Proof
</summary>
<p>The proof follows a very similar argument to 3.1,</p>
<p><span class="math display">\[\begin{align}
\frac{\der \ln \l(t)}{\der t} &amp;= -\frac{|\nabla f(w)|^2}{f(w)} \quad &amp;\text{(result 1.3)} \\
&amp;\le - \alpha + \beta \;  |w - w_0| \\
&amp;\le - \alpha + \beta \sqrt {\l(0) t} \quad &amp;\text{(result 1.5)} \\
\end{align}\]</span></p>
<p>Integrating both sides from <span class="math inline">\(0\)</span> to <span class="math inline">\(t\)</span> we get <span class="math display">\[
\ln \l(t) - \ln \l(0) \le - \alpha t + \frac{2}{3}  \beta \sqrt {\l(0)} \; t^{3/2}
\]</span></p>
<p>which implies <span class="math display">\[
\l(t) \le \l(0) \exp(- \alpha t + \frac{2}{3}  \beta \sqrt \l(0) \; t^{3/2})
\]</span></p>
<p>Now, we want to find the value of <span class="math inline">\(t\)</span> that minimizes the term in the exponential. We set the derivative to <span class="math inline">\(0\)</span> by solving <span class="math inline">\(- \alpha t + \frac{2}{3}  \beta \sqrt {\l(0)} \; t^{3/2}=0\)</span> which you can easily is achieved at <span class="math inline">\(t^* = \frac {\alpha^2} {\beta^2 \l(0)}\)</span>. This implies that, <span class="math display">\[
\l(t^*) \le \l(0) \exp({-\frac{\alpha^3}{3\beta^2 \l(0)}})
\]</span> And, since <span class="math inline">\(\l'(t) = -|\nabla f \circ \gamma(t)|^2 \le 0\)</span>, the loss function is monotonically decreasing, which implies that <span class="math inline">\(\l(\infty) \le \l(t^*) \le \l(0)\exp({-\frac{\alpha^3}{3\beta^2 \l(0)}})\)</span>, proving the result.</p>
</details>
</section>
<section id="the-simplest-neural-network" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-simplest-neural-network">3. The Simplest Neural Network</h2>
<p>The objective of this section is straightforward. To take the absolute simplest neural network and show that the conditions of Result 2.2 are satisfied. We’ll look at a 2-layer MLP with ReLU nonlinearity. It has two parameter matrices <span class="math inline">\(M\in \R^{k\times m}\)</span> and <span class="math inline">\(N\in \R^{n\times k}\)</span>. The ReLU is denoted by <span class="math inline">\(\sigma\)</span>. Given an input <span class="math inline">\(x \in \R^m\)</span>, the MLP produces the output <span class="math display">\[
y = N \sigma(M x)
\]</span> It is convenient to define intermediate variables by breaking down the computation into steps. <span class="math display">\[
a = Mx, \quad b=\sigma(a) \quad y=Nb
\]</span> <strong>Parameter space.</strong> The weight vectors are pairs of matrices <span class="math inline">\(w = (N, M)\)</span> and so the parameter space is <span class="math display">\[W= \R^{n\times k} \oplus \R^{k\times m}\]</span> <strong>The loss function.</strong> In keeping with the philosophy of studying the simplest example, we’ll take the loss function to be the L2 error on a single input-target pair <span class="math inline">\((x, q)\in \R^n \oplus \R^m\)</span>. <span class="math display">\[
f(w) = \frac 1 2 |y - q|^2
\]</span> We will need <span class="math inline">\(x\)</span> to be normalized, so we just assume that <span class="math inline">\(|x|^2 = m\)</span>. It’s also useful to define the loss as a variable <span class="math inline">\(L = f(w)\)</span>.</p>
<p><strong>Initialization.</strong> The standard way to initialize a neural network is to independently sample all the entries in the weight matrices from some distribution. In our case, we use <span class="math display">\[
M_{ij} \sim \mathcal N (0, {\small \frac 2 m} ) \quad\quad N_{ij} \sim \mathcal N (0, {\small \frac 2 k})
\]</span> This is the commonly-used <a href="https://arxiv.org/abs/1502.01852">He initialization</a>, which works well for networks with ReLU nonlinearities. This initialization provides us with the guarantee that, with high probability, <span class="math display">\[
|b|^2 \simeq k
\]</span></p>
<details>
<summary>
See a derivation of this property
</summary>
<p>Remember that we are sampling the initial weight matrices via <span class="math display">\[
M_{ij} \sim \mathcal N (0, {\small \frac 2 m} ) \quad\quad N_{ij} \sim \mathcal N (0, {\small \frac 2 k})
\]</span> Since <span class="math inline">\(M,N\)</span> are random variables, so are <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. He initialization uses carefully-chosen variances to ensure that the entries of the initial activations <span class="math inline">\(a = M x\)</span> and <span class="math inline">\(b = \sigma(a)\)</span> are within some reasonable range. In particular, we want the entries of <span class="math inline">\(b_i\)</span> to have <span class="math inline">\(0\)</span> mean and variance <span class="math inline">\(1\)</span>. And since all the entries are independent, that will mean that <span class="math inline">\(|b|^2 \simeq k\)</span> and so <span class="math inline">\(b\)</span> will be close to the sphere of radius <span class="math inline">\(\sqrt k\)</span> with high probability. (But this is only the case if the input vector is also normalized; that is why we needed the assumption that <span class="math inline">\(|x|^2 = m\)</span>.) We will now prove these statements.</p>
First we want to understand <span class="math inline">\(\E[a_i^2]\)</span> <span class="math display">\[\begin{align}
\E[a_i^2]
&amp;= \E[ ({\small \sum_j M_{ij} x_j})^2] \\
&amp;= \E[ {\small \sum_j M_{ij}^2 x_j^2 + \sum_{k\neq j} M_{ij} x_j M_{ik} x_k } ] \\
&amp;= \sum_j \E[M_{ij}^2 x_j^2] \\
&amp;= \frac 2 m |x|^2= 2
\end{align}\]</span> where we used the independence of different entries of <span class="math inline">\(M\)</span> and the fact that <span class="math inline">\(\E[M_{ij}]=0\)</span>. Then <span class="math display">\[
\E[|a|^2] = \sum_i \E[a_i^2] = 2k
\]</span> Let <span class="math inline">\(p_M\)</span> denote the probability distribution functions (PDFs) of the entries of <span class="math inline">\(M_{ij}\)</span> (all entries have the same PDF because they are independent and identically distributed). The PDF of <span class="math inline">\(a_i\)</span> will be the nested integral of <span class="math inline">\(\delta(a_i - M_i^T x)\)</span> as <span class="math inline">\(M_{i1},\cdots,M_{im}\)</span> range from <span class="math inline">\(-\infty \to \infty\)</span>, where <span class="math inline">\(\delta\)</span> denote the Dirac delta function. <span class="math display">\[
p_{a}(z) = \int_{-\infty}^\infty \cdots \int_{-\infty}^\infty p_M(M_{i1}) \cdots p_M(M_{im}) \; \delta (z - M_i^T x)\; d M_{i1} \cdots d M_{im}
\]</span> Recall that a distribution is symmetric if <span class="math inline">\(p(z) = p(-z)\)</span>. Since <span class="math inline">\(p_M\)</span> is a Gaussian, it is symmetric. The next thing we need to prove is that <span class="math inline">\(p_a\)</span> is symmetric too. <span class="math display">\[\begin{align}
p_{a}(z) &amp;= \int_{-\infty}^\infty \cdots \int_{-\infty}^\infty p_M(M_{i1}) \cdots p_M(M_{im}) \; \delta (z - M_i^T x)\; d M_{i1} \cdots d M_{im} \\
&amp;=  \int_{-\infty}^\infty \cdots \int_{-\infty}^\infty p_M(-M_{i1}) \cdots p_M(-M_{im}) \; \delta (z + M_i^T x)\; d M_{i1} \cdots d M_{im} \\
&amp;=  \int_{-\infty}^\infty \cdots \int_{-\infty}^\infty p_M(M_{i1}) \cdots p_M(M_{im}) \; \delta (-z - M_i^T x)\; d M_{i1} \cdots d M_{im} \\
&amp;= p_a(-z)
\end{align}\]</span> The first step uses the change of variable <span class="math inline">\(M_{ij}\to -M_{ij}\)</span>, and the second one exploits the symmetry of <span class="math inline">\(p_M\)</span> and <span class="math inline">\(\delta\)</span>. Finally, we compute the term we care about: <span class="math display">\[\begin{align}
\E[b_i^2] &amp;= \int_{-\infty}^\infty p_a(a_i) \sigma(a_i)^2 da_i \\
&amp;= \int_{-\infty}^0 p_a(a_i) \:0\: da_i + \int_0^\infty p_a(a_i) a_i^2 da_i \\
&amp;= \frac 1 2 \int_{-\infty}^\infty p_a(a_i) a_i^2 da_i \quad \text{(using symmetry)}\\
&amp;= \frac 1 2 \E[a_i^2] \\
&amp;= k
\end{align}\]</span> We have only been working out <span class="math inline">\(\E[|b|^2] = k\)</span>, but we wanted to make claims about the particular samples themselves being approximately <span class="math inline">\(|b|^2\simeq k\)</span>. The rigorous way to go about doing so would be to prove statements like <span class="math inline">\(\Pr( k - \epsilon \le |b|^2 \le k+\epsilon) \le \alpha\)</span>. But this type of argument is very tedious and adds little insight about the ideas this document is exploring, so instead, in the rest of this article we just assume that <span class="math inline">\(|b|^2 = k\)</span>. When the dimension <span class="math inline">\(k\)</span> is large, this approximation will be very accurate.
</details>
<p><strong>Gradients.</strong> The gradients of the loss <span class="math inline">\(\l\)</span> wrt all the intermediate variables and weights are: <span class="math display">\[
\ht y = y -q, \quad
\ht b = N^T \ht y, \quad
\ht a =\der \sigma(a)^T \ht b, \quad
\ht M = \ht a x^T, \quad
\ht N = \ht y b^T, \quad
\]</span></p>

<div class="no-row-height column-margin column-container"><div class="">
<p>In this notation, a hat on top of a variable denotes the gradient of the loss function wrt that variable.</p>
</div></div><details>
<summary>
Expand for full derivation of the gradients.
</summary>
<p>Note that <span class="math inline">\(|\hat y |^2 = 2 \l\)</span> so, when the loss is large, the gradient of <span class="math inline">\(\l\)</span> wrt <span class="math inline">\(y\)</span> is large too. Ultimately we are trying to show something similar, but about gradients of <span class="math inline">\(\l\)</span> wrt <span class="math inline">\(M\)</span> (in order to then apply Result 2.2.)</p>
<p>Below, we’ve written a short derivation of all these gradient formulas, but using some unconventional notation and techniques. If you find them confusing, just work out the gradients in your own way and confirm you get the same answers.</p>
Starting with <span class="math inline">\(\ht y\)</span>, the gradient of <span class="math inline">\(\l\)</span> wrt <span class="math inline">\(y\)</span>. Let <span class="math inline">\(\dot y \in \R^n\)</span> denote an arbitrary change to <span class="math inline">\(y\)</span>. Then <span class="math display">\[\begin{align}
&lt;\ht y, \dot y&gt; =\frac {\der \l} {\der y} (\dot y)
&amp;\simeq \frac 1 2 |y +\dot y - q|^2 - \frac 1 2 |y - q|^2 \\
&amp;= \frac 1 2 ( &lt;\dot y, y-q&gt; + &lt;\dot y, \dot y&gt; + &lt;y-q, \dot y&gt; ) \\
&amp;\simeq &lt;y-q, \dot y&gt; \quad \text{(dropping the lower order term)} \\
\end{align}\]</span> Now, let’s see how a change in <span class="math inline">\(b\)</span> affects <span class="math inline">\(y\)</span>. Like before, let <span class="math inline">\(\dot b\)</span> denote a change to <span class="math inline">\(b\)</span>. The derivative <span class="math inline">\(\frac {\der y}{\der b}(\dot b) \simeq N(b+ \dot b) - M b = \dot M b\)</span>. So, the gradient of <span class="math inline">\(\l\)</span> wrt <span class="math inline">\(b\)</span> satisfies <span class="math display">\[
&lt;\ht b, \dot b&gt;
= {\frac {\der \l}{\der b}(\dot b)}
= {\frac {\der \l}{\der y}} \left(  {\frac {\der y}{\der b}}(\dot b) \right)
=  &lt;\ht y,  {\frac {\der y}{\der b}} (\dot b)&gt;
= &lt;\hat y, M \dot b&gt; = &lt;M^T \ht y, \dot b&gt;
\]</span> Now, let’s look at <span class="math inline">\(N\)</span>. The derivative <span class="math inline">\(\frac {\der y}{\der N}(\dot N) \simeq (N+\dot N) b - N b = \dot N b\)</span>. And the gradient <span class="math display">\[
&lt;\ht N, \dot N&gt;  = &lt;\ht y, \dot N b&gt; = &lt;\ht y b^T, \dot N&gt;
\]</span> Recall that, since we are taking the inner product of two matrices, we are using the trace under the hood. To see why the last step is true, just use the cyclic property of the trace. Finally, gradients of <span class="math inline">\(a\)</span> and <span class="math inline">\(M\)</span>: <span class="math display">\[\begin{gather}
&lt;\hat a, \dot a&gt;
= &lt;\hat b, \der \sigma(a)(\dot a)&gt;
= &lt;\der \sigma(a)^T \ht b, \dot a&gt;  \\
&lt;\ht M, \dot M&gt;
= &lt;\ht a, \dot M x&gt; = &lt;\ht a x^T, \dot M&gt;
\end{gather}\]</span>
</details>
<p>Note that <span class="math inline">\(|\hat y|^2 = 2 f(w) = L\)</span>, the gradient of the loss wrt the output, is proportional to the loss itself.</p>
<p><strong>Gradient health.</strong> The gradient of the loss wrt the matrix <span class="math inline">\(N\)</span> satisfies <span class="math display">\[
|\ht{N} |^2
\ge 2 L ( k - 2 \sqrt {k} |w_0 - w| ) \\
\]</span></p>
<details>
<summary>
Expand for activation and gradient bounds.
</summary>
<p>First, let’s review a basic fact. Given a matrix <span class="math inline">\(A\in \R^{n\times m}\)</span> and <span class="math inline">\(x\in \R^m\)</span> we have that <span class="math inline">\(|Ax| \le |A| \; |x|\)</span>. This follows form the SVD decomposition <span class="math inline">\(A = R \Lambda S^T\)</span>, where <span class="math inline">\(R,S\)</span> are orthogonal matrices and <span class="math inline">\(\Lambda\)</span> is a diagonal matrix with the singular values <span class="math inline">\(\lambda_1,\cdots, \lambda_n \ge 0\)</span> in it’s diagonal. First, note that <span class="math display">\[
|A^T A |^2 = | S \Lambda^2 S^T|^2 = | \Lambda^2 |^2 = \sum_i \lambda_i^4 \le \left( \sum_i \lambda_i^2 \right)^2 = | \Lambda |^4 = | R \Lambda S^T|^4 = | A |^4
\]</span> So <span class="math display">\[\begin{align}
|A x|^2 &amp;= \tr(x^T A^T A x) = \tr(A^T A x x^T) = &lt;A^T A, x x^T&gt; \\
&amp;\le  |A^T A| |x x^T| = |A^T A| |x|^2 \\
&amp;\le |A|^2 |x|^2
\end{align}\]</span></p>
<p>Now, recall that <span class="math inline">\(w_0 = (M_0, N_0)\)</span> and let <span class="math inline">\(a_0=M_0 x, b_0=\sigma(a_0)\)</span> and <span class="math inline">\(y_0=N_0 b_0\)</span> be the activations at initialization. We want to derive upper bounds on <span class="math inline">\(|a - a_0|\)</span> and <span class="math inline">\(|b - b_0|\)</span> based on <span class="math inline">\(|w-w_0|\)</span>. First, <span class="math display">\[\begin{align*}
|a_0 - a| &amp;\le |M_0 x - Mx| \\
          &amp; = |M_0 - M| \; |x| \quad \text{(using the fact we just proved)} \\
          &amp; \le |w-w_0| \; |x| \\
          &amp; = \sqrt m \; |w-w_0|
\end{align*}\]</span> where the last step used the assumption that <span class="math inline">\(|x| = \sqrt m\)</span> (the inputs are normalized). To bound <span class="math inline">\(|b_0 - b |\)</span> we need to use the fact that the ReLU <span class="math inline">\(\sigma\)</span> is 1-Lipschitz. So <span class="math display">\[
|b_0 - b| = |\sigma(a) - \sigma(a_0) | \le |a_0 - a | \le \sqrt m \; |w-w_0|
\]</span></p>
Recall that our weight initialization guarantees that <span class="math inline">\(|b_0| \simeq \sqrt k\)</span> (for simplicity we assume exact equality). Now we can conclude with: <span class="math display">\[\begin{align}
| \ht{N} |^2 &amp;= |\ht y b^T|^2 = \text{trace}(b y^T y b^T)
              = |\ht{y}|^2 |b|^2
              = 2 L |b|^2 \\
              &amp;\ge L (|b_0|  - |b_0 - b|)^2
              = 2 L ( \sqrt k - |b_0 - b| )^2 \\
              &amp;= 2 L ( k - 2 \sqrt k |b_0 - b| +  |b_0 - b| ^2 ) \\
              &amp;\ge 2 L ( k - 2 \sqrt k |b_0 - b| ) \\
              &amp;\ge 2 L ( k - 2 \sqrt {km} |w_0 - w| ) \\
\end{align}\]</span>
</details>
<p>We could also attempt to derive a lower bound for <span class="math inline">\(|\ht M|^2\)</span>, but it is not really necessary to do so. We already have enough to apply 2.2.</p>
<p><strong>Learning Guarantees.</strong> Since <span class="math inline">\(|\nabla f(w)|^2 = |\ht N|^2 + |\ht N|^2\)</span>, the previous result implies that <span class="math display">\[
\frac{|\nabla f(w)|^2}{f(w)} \ge 2k - 4 \sqrt {km} |w_0 - w|\\
\]</span> So by setting <span class="math inline">\(\alpha = 2k\)</span> and <span class="math inline">\(\beta = 4 \sqrt {km}\)</span>, the application of Result 2.2 gives <span class="math display">\[
l(\infty) \le \l(0) \; \text{exp}({-\frac {k^2}{6 m \l(0)} })
\]</span> From looking at the above equation, it is apparent that the scale of the MLP helps it learn. By growing <span class="math inline">\(k\)</span> we can very quickly guarantee that the loss is decreased to any desired value.</p>
<p>Play with the interactive visualization to see how this simple 2-layer MLP learns. The red line shows to this bound we’ve just derived.</p>
<div id="root">

</div>

</section>

<div id="quarto-appendix" class="default"><section id="acknowledgments" class="level3 appendix"><h2 class="anchored quarto-appendix-heading">Acknowledgments</h2><div class="quarto-appendix-contents">

<p>Huge thanks to <a href="https://x.com/nahrzf">Nahr</a> for constructing the live training visualizations of the post and to Sean Zhang for bringing relevant literature to our attention.</p>
<script src="./dist/runtime.bundle.js"></script>
<script src="./dist/vendor.bundle.js"></script>
<script src="./dist/main.bundle.js"></script>



</div></section><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list">
<div id="ref-zhang2017understandingdeeplearningrequires" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">C. Zhang, S. Bengio, M. Hardt, B. Recht, and O. Vinyals, <span>“Understanding deep learning requires rethinking generalization.”</span> 2017. Available: <a href="https://arxiv.org/abs/1611.03530">https://arxiv.org/abs/1611.03530</a></div>
</div>
<div id="ref-bubeck2015convex" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">S. Bubeck <em>et al.</em>, <span>“Convex optimization: Algorithms and complexity,”</span> <em>Foundations and Trends<span></span> in Machine Learning</em>, vol. 8, no. 3–4, pp. 231–357, 2015.</div>
</div>
<div id="ref-du2019gradientdescentfindsglobal" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">S. S. Du, J. D. Lee, H. Li, L. Wang, and X. Zhai, <span>“Gradient descent finds global minima of deep neural networks.”</span> 2019. Available: <a href="https://arxiv.org/abs/1811.03804">https://arxiv.org/abs/1811.03804</a></div>
</div>
<div id="ref-allenzhu2019convergencetheorydeeplearning" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">Z. Allen-Zhu, Y. Li, and Z. Song, <span>“A convergence theory for deep learning via over-parameterization.”</span> 2019. Available: <a href="https://arxiv.org/abs/1811.03962">https://arxiv.org/abs/1811.03962</a></div>
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{gelada2024,
  author = {Gelada, Carles and Buckman, Jacob},
  publisher = {Manifest AI},
  title = {Why {Gradient} {Descent} {Minimizes} {Training} {Loss}},
  date = {2024-09-23},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-gelada2024" class="csl-entry quarto-appendix-citeas" role="listitem">
<div class="">C.
Gelada and J. Buckman, <span>“Why Gradient Descent Minimizes Training
Loss.”</span> Manifest AI, Sep. 23, 2024.</div>
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="m-a-n-i-f-e-s-t/website" data-repo-id="R_kgDOLA6vSg" data-category="Announcements" data-category-id="DIC_kwDOLA6vSs4Cgv3x" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" data-loading="lazy" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>© 2024 Manifest AI</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>